{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:66ch;\">\n",
    "\n",
    "# Lecture notes - linear regression\n",
    "\n",
    "This is the lecture note for **linear regression** using scikit-learn. We \n",
    "\n",
    "<p class = \"alert alert-info\" role=\"alert\"><b>Note</b> that this lecture note gives a brief introduction to linear regression and using scikit-learn. You are encouraged to read more about this topic, see the resources for this week to find out more. \n",
    "\n",
    "- [scikit-learn](https://scikit-learn.org/stable/)\n",
    "- [train-test split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html?highlight=train%20test#sklearn.model_selection.train_test_split)\n",
    "- [scaling data](https://machinelearningmastery.com/standardscaler-and-minmaxscaler-transforms-in-python/)\n",
    "- [LinearRegression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html)\n",
    "- [SGDRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDRegressor.html)\n",
    "- [mean_absolute_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html?highlight=mean%20absolute#sklearn.metrics.mean_absolute_error)\n",
    "- [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html?highlight=mean%20squared#sklearn.metrics.mean_squared_error)\n",
    "- [OLS](https://scikit-learn.org/stable/modules/linear_model.html#ordinary-least-squares)\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:66ch;\">\n",
    "\n",
    "## Advertisement data\n",
    "\n",
    "We will perform multiple linear regression on the same [advertisement data](https://www.statlearning.com/resources-second-edition) that we worked on in lecture 0. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 samples\n",
      "3 features\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TV</th>\n",
       "      <th>Radio</th>\n",
       "      <th>Newspaper</th>\n",
       "      <th>Sales</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230.1</td>\n",
       "      <td>37.8</td>\n",
       "      <td>69.2</td>\n",
       "      <td>22.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44.5</td>\n",
       "      <td>39.3</td>\n",
       "      <td>45.1</td>\n",
       "      <td>10.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17.2</td>\n",
       "      <td>45.9</td>\n",
       "      <td>69.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>151.5</td>\n",
       "      <td>41.3</td>\n",
       "      <td>58.5</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>180.8</td>\n",
       "      <td>10.8</td>\n",
       "      <td>58.4</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      TV  Radio  Newspaper  Sales\n",
       "1  230.1   37.8       69.2   22.1\n",
       "2   44.5   39.3       45.1   10.4\n",
       "3   17.2   45.9       69.3    9.3\n",
       "4  151.5   41.3       58.5   18.5\n",
       "5  180.8   10.8       58.4   12.9"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"../data/Advertising.csv\", index_col=0)\n",
    "\n",
    "print(f\"{df.shape[0]} samples\")\n",
    "print(f\"{df.shape[1]-1} features\") # subtract one as price_unit_area is the label and not    \n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:66ch;\">\n",
    "\n",
    "### Dependent and independent variable\n",
    "\n",
    "Each **feature** TV, Radio and Newspaper are considered independent variables or features and the Sales is the dependent variable as its value depends on the values of the features. Sales can also be considered the **label**. \n",
    "\n",
    "The features can be represented by a matrix X and label can be represented by a vector y. In this case y consists of continous data, and the problem we have is **regression**.  \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      TV  Radio  Newspaper\n",
       " 1  230.1   37.8       69.2\n",
       " 2   44.5   39.3       45.1,\n",
       " 1    22.1\n",
       " 2    10.4\n",
       " Name: Sales, dtype: float64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, y = df.drop(\"Sales\", axis=\"columns\"), df[\"Sales\"]\n",
    "X.head(2), y.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:66ch;\">\n",
    "\n",
    "## Scikit-learn steps\n",
    "\n",
    "Instead of coding out the details how to manually perform linear regression, we will be using a very common library called scikit-learn for it. If you are interested it is great to code it out manually, as you'll get deeper understanding of how the algorithm works. Note that it requires some basic knowledge of linear algebra. \n",
    "\n",
    "Now we'll move on to scikit-learn which will work for most classical machine learning algorithms. There are a few steps to follow that will be very familiar for you. However depending on situation, algorithm, dataset, some steps might need to be omitted or additional steps required. \n",
    "\n",
    "Steps: \n",
    "1. train|test split - some cases train|validation|test - split\n",
    "2. Scale the dataset \n",
    "    - many algorithms require scaling, some don't\n",
    "    - which type of scaling to use?\n",
    "    - scale training data, test data to the training data, to avoid data leakage\n",
    "3. Fit the algorithm to the training data\n",
    "4. Transform the training data, transform the test data\n",
    "5. Calculate evaluation metrics\n",
    "\n",
    "Also if using validation dataset there are some more steps in fine tuning hyperparameters.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:66ch;\">\n",
    "\n",
    "### 1. Train|test split\n",
    "\n",
    "So how well did the model perform? There are several evaluation metrics that we can use to answer this question but not on the training data. Using training data for evaluation we have **data leakage**, because at prediction time we shouldn't have this data available. Data leakage will lead to overestimation of the performance as the model has already trained on the data it is using for evaluation.\n",
    "\n",
    "We split the data into a training set and a test set, where the test set will only be used during evaluation of the model. Practically we randomly sample this dataset without replacement with certain size for training set and the rest for testing.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((140, 3), (60, 3), (140,), (60,))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:66ch;\">\n",
    "\n",
    "### 2. Feature scaling\n",
    "\n",
    "Two popular scaling techniques are normalization and feature standardization\n",
    "\n",
    "Normalization (min-max feature scaling)\n",
    "\n",
    "- $X' = \\frac{X-X_{min}}{X_{max}-X_{min}}$\n",
    "\n",
    "Feature standardization (standard score scaling)\n",
    "\n",
    "- $X' = \\frac{X - \\mu}{\\sigma}$\n",
    "\n",
    "\n",
    "A question arises when to use one over the other and here are some considerations: \n",
    "\n",
    "\n",
    "<table border=\"1\" style=\"text-transform: lowercase; display:inline-block; text-align:left;\">\n",
    "    <tr style=\"background-color: #174A7E; color: white;\">\n",
    "        <th>Algorithm</th>\n",
    "        <th>When to use</th>\n",
    "        <th>Benefits</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Feature standardization</td>\n",
    "        <td>Scale to 0 mean and unit variance, good when algorithm assumes normal distribution or the data is normally distributed.</td>\n",
    "        <td>Preserves shape of original distribution.</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>Normalization (min-max)</td>\n",
    "        <td>Scaling features to fall within range of 0-1, and good when not assume specific distribution of data like neural networks and for algorithms sensitive to scale such as KNN.</td>\n",
    "        <td>Transform feature to common scale without distorting ranges of values.</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Note that you can also consider which type of scaling as a hyperparameter in which you choose and see how it affects your validation datas performance.\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00 ≤ scaled_X_train ≤ 1.00\n",
      "0.01 ≤ scaled_X_test ≤ 1.13\n"
     ]
    }
   ],
   "source": [
    "# we use normalization here\n",
    "# instantiate an object from the class MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train) # use the training data to fit the scaler\n",
    "\n",
    "# very important that we fit to training data, i.e. use training datas parameters to transform \n",
    "# both training and test data, else if we use test datas parameters to scale test data, we have \n",
    "# leaked data, which might give misleading results \n",
    "scaled_X_train = scaler.transform(X_train)\n",
    "scaled_X_test = scaler.transform(X_test)\n",
    "\n",
    "print(f\"{scaled_X_train.min():.2f} ≤ scaled_X_train ≤ {scaled_X_train.max():.2f}\")\n",
    "print(f\"{scaled_X_test.min():.2f} ≤ scaled_X_test ≤ {scaled_X_test.max():.2f}\") # natural that it isn't [0,1] since we fit to training data \n",
    "\n",
    "# we do not scale our target variable y in this lecture "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Linear regression\n",
    "\n",
    "Use linear regression to fit to training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters: [13.02832938  9.88465985  0.69237469]\n",
      "Intercept parameter: 2.741855324852814\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# this model uses SVD approach for solving normal equation\n",
    "model = LinearRegression()\n",
    "model.fit(scaled_X_train, y_train)\n",
    "print(f\"Parameters: {model.coef_}\")\n",
    "print(f\"Intercept parameter: {model.intercept_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled features [[0.54988164 0.63709677 0.52286282]], label 16.9\n",
      "Prediction: 16.57\n"
     ]
    }
   ],
   "source": [
    "test_sample_features = scaled_X_test[0].reshape(1,-1)\n",
    "test_sample_target = y_test.values[0]\n",
    "\n",
    "print(f\"Scaled features {test_sample_features}, label {test_sample_target}\")\n",
    "print(f\"Prediction: {model.predict(test_sample_features)[0]:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:66ch;\">\n",
    "\n",
    "### 4. Predict on test data\n",
    "\n",
    "Use the test data scaled to X_train and predict on it. \n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.51, MSE: 3.80, RMSE: 1.95\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
    "\n",
    "# first predict on our test data\n",
    "y_pred = model.predict(scaled_X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:66ch;\">\n",
    "\n",
    "## 5. Evaluate performance\n",
    "\n",
    "How well did we predict $\\bf{y}$ (label) with $\\hat{\\bf{y}}$ (y_pred)?\n",
    "\n",
    "To answer this question we use several **evaluation metrics** or **loss functions**: \n",
    "\n",
    "- Mean Absolute Error (MAE) - mean of error between $\\bf{y}$ and ${\\hat{\\bf{y}}}$. The unit is same as measured quantity.\n",
    "\n",
    "$$MAE = \\frac{1}{m}\\sum_{i=1}^m |y_i - \\hat{y}_i|$$\n",
    "\n",
    "- Mean Squared Error (MSE) - mean of squared errors between $\\bf{y}$ and ${\\hat{\\bf{y}}}$. It punishes large errors, and the units are in square units of the measured quantity\n",
    "\n",
    "$$MSE = \\frac{1}{m}\\sum_{i=1}^m (y_i - \\hat{y}_i)^2$$\n",
    "\n",
    "- Root Mean Squared Error (RMSE) - square root of MSE between $\\bf{y}$ and ${\\hat{\\bf{y}}}$. It punishes large errors, and the units are same as measured quantity, hence easier to interpret.\n",
    "\n",
    "$$RMSE = \\sqrt{\\frac{1}{m}\\sum_{i=1}^m (y_i - \\hat{y}_i)^2}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 1.51, MSE: 3.80, RMSE: 1.95\n"
     ]
    }
   ],
   "source": [
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(f\"MAE: {mae:.2f}, MSE: {mse:.2f}, RMSE: {rmse:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### next steps ... \n",
    "\n",
    "now you can train on all available data and use that for predicting new data points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"max-width:66ch;\">\n",
    "\n",
    "## Summary\n",
    "\n",
    "In this lecture we've covered the very basics of scikit-learn and its use for linear regression. These steps are crucial for many machine learning algorithms, so try learning them, and try to understand the details of why we do them.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #FFF; color: #212121; border-radius: 1px; width:22ch; box-shadow: rgba(0, 0, 0, 0.16) 0px 1px 4px; display: flex; justify-content: center; align-items: center;\">\n",
    "<div style=\"padding: 1.5em 0; width: 70%;\">\n",
    "    <h2 style=\"font-size: 1.2rem;\">Kokchun Giang</h2>\n",
    "    <a href=\"https://www.linkedin.com/in/kokchungiang/\" target=\"_blank\" style=\"display: flex; align-items: center; gap: .4em; color:#0A66C2;\">\n",
    "        <img src=\"https://content.linkedin.com/content/dam/me/business/en-us/amp/brand-site/v2/bg/LI-Bug.svg.original.svg\" width=\"20\"> \n",
    "        LinkedIn profile\n",
    "    </a>\n",
    "    <a href=\"https://github.com/kokchun/Portfolio-Kokchun-Giang\" target=\"_blank\" style=\"display: flex; align-items: center; gap: .4em; margin: 1em 0; color:#0A66C2;\">\n",
    "        <img src=\"https://github.githubassets.com/images/modules/logos_page/GitHub-Mark.png\" width=\"20\"> \n",
    "        Github portfolio\n",
    "    </a>\n",
    "    <span>AIgineer AB</span>\n",
    "<div>\n",
    "</div>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-part-1-handelsakademin-5RQamIMR-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
