# Week 15 - Resources

Note that the resource material is very extensive and you are not required to read them all. See it as a reference material, which you always can come back to. 

## Video guides :video_camera:

**Decision tree:**
- [Decision tree classification - Normalized Nerd](https://www.youtube.com/watch?v=ZVR2Way4nwQ)
- [Decision tree regression - Normalized Nerd](https://www.youtube.com/watch?v=UhY5vPfQIrA&list=RDCMUC7Fs-Fdpe0I8GYg3lboEuXw&index=3)

**Random forest**
- [Random forest](https://www.youtube.com/watch?v=v6VJ2RO66Ag)

**XGBoost**
- [XGBoost part 1 regression - StatQuest (2020)](https://www.youtube.com/watch?v=OtD8wVaFm6E)
- [XGBoost part 2 classification - StatQuest (2020)](https://www.youtube.com/watch?v=8b1JEDvenQU)
- [XGBoost part 3 mathematical details - StatQuest (2020)](https://www.youtube.com/watch?v=ZVFeW798-2I)
- [XGBoost part 4 optimizations - StatQuest (2020)](https://www.youtube.com/watch?v=oRrKeUCEbq8)

## Theory :book:

**Decision Tree**
- [ISLRv2 chapter 8.1 pp. 327-339](https://link)
- [DecisionTreeClassifier sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)
- [DecisionTreeRegressor sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html#sklearn.tree.DecisionTreeRegressor)
- [Decision trees sklearn theory](https://scikit-learn.org/stable/modules/tree.html)
- [Decision tree learning wikipedia](https://en.wikipedia.org/wiki/Decision_tree_learning)
- [Lecture slides chapter 8 - ISLR](https://hastie.su.domains/ISLR2/Slides/Ch8_Tree_Based_Methods.pdf)
- [ISLRv2 pp. 327-352](https://www.statlearning.com/)

**Random forest**
- [RandomForestRegressor - sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html)
- [RandomForestClassifier - sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html)
- [Tune hyperparameters - towardsdatascience](https://towardsdatascience.com/random-forest-hyperparameters-and-how-to-fine-tune-them-17aee785ee0d)
- [Random forest - wikipedia](https://en.wikipedia.org/wiki/Random_forest)
- [Lecture slides chapter 8 - ISLR](https://hastie.su.domains/ISLR2/Slides/Ch8_Tree_Based_Methods.pdf)
- [ISLRv2 pp. 327-352](https://www.statlearning.com/)

**XGBoost**
- [sklearn estimator interface - xgboost documentation](https://xgboost.readthedocs.io/en/latest/python/sklearn_estimator.html)
- [XGBoost tutorial - xgboost documentation](https://xgboost.readthedocs.io/en/latest/tutorials/index.html)
- [gradient boosting - wikipedia](https://en.wikipedia.org/wiki/Gradient_boosting)
- [how to train XGBoost in Python - Lianne and Justing (2023)](https://www.youtube.com/watch?v=aLOQD66Sj0g)
- [Target Encoder - Category Encoders](https://contrib.scikit-learn.org/category_encoders/targetencoder.html)
- [scikit-optimize documentation](https://scikit-optimize.github.io/stable/)
- [Scikit-learn hyperparameter search wrapper - Shcherbatyi (2017) et. al.](https://scikit-optimize.github.io/stable/auto_examples/sklearn-gridsearchcv-replacement.html)
- [BayesSearchCV - scikit-optimize](https://scikit-optimize.github.io/stable/modules/generated/skopt.BayesSearchCV.html)

**KMeans**
- [Color quantization - wikipedia](https://en.wikipedia.org/wiki/Color_quantization)
- [Clustering user guide - sklearn](https://scikit-learn.org/stable/modules/clustering.html#k-means)
- [KMeans - sklearn](https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html)
- [Find optimal k clusters - analyticsvidhya](https://www.analyticsvidhya.com/blog/2021/05/k-mean-getting-the-optimal-number-of-clusters/)
- [ISLRv2 - pp. 516-521](https://www.statlearning.com/)

## Lecture notes :mortar_board:

- lecture theory 07-10
- lecture code 07-10

## Exercises :running:

Focus on lab 1 and also work with older exercises if you haven't finished them yet. 
